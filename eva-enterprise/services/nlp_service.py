"""
Servi√ßo de NLP para an√°lise de conversas e detec√ß√£o de risco
"""
import re
import logging
from typing import List, Dict, Tuple, Optional
from datetime import datetime

logger = logging.getLogger(__name__)


class NLPService:
    """Servi√ßo para an√°lise de linguagem natural em sa√∫de mental"""

    # =====================================================================
    # KEYWORDS PERIGOSAS (Detec√ß√£o de Risco)
    # =====================================================================

    DANGER_KEYWORDS = {
        'suicidal_ideation': [
            'suic√≠dio', 'me matar', 'acabar com tudo', 'n√£o aguento mais',
            'quero morrer', 'melhor morto', 'fim da vida', 'tirar minha vida',
            'n√£o vale a pena viver', 'desaparecer', 'dormir para sempre',
            '√∫ltima vez', 'despedida', 'n√£o quero mais viver'
        ],
        'self_harm': [
            'me cortar', 'me machucar', 'automutila√ß√£o', 'me ferir',
            'cortar os pulsos', 'queimar', 'me bater'
        ],
        'hopelessness': [
            'sem esperan√ßa', 'sem sa√≠da', 'sem futuro', 'nada vai melhorar',
            'nunca vai passar', 'imposs√≠vel', 'desistir', 'dar up',
            'in√∫til', 'fracasso total', 'perdido'
        ],
        'isolation': [
            'ningu√©m liga', 'sozinho', 'abandonado', 'ningu√©m se importa',
            'invis√≠vel', 'sem amigos', 'sem fam√≠lia', 'isolado'
        ],
        'severe_depression': [
            'vazio', 'nada me alegra', 'sem sentido', 'buraco negro',
            'peso enorme', 'escurid√£o', 'dor insuport√°vel'
        ],
        'severe_anxiety': [
            'p√¢nico', 'sufocando', 'cora√ß√£o acelerado', 'vou morrer',
            'descontrole', 'terror', 'medo de tudo'
        ],
        'substance_abuse': [
            '√°lcool demais', 'bebendo muito', 'usando drogas', 'depend√™ncia',
            'preciso beber', 'sem controle com bebida'
        ]
    }

    # =====================================================================
    # POSITIVE KEYWORDS (Indicadores de Bem-Estar)
    # =====================================================================

    POSITIVE_KEYWORDS = {
        'gratitude': [
            'grato', 'agradecido', 'sortudo', 'aben√ßoado', 'feliz por',
            'apreciando', 'valorizo'
        ],
        'hope': [
            'esperan√ßa', 'vai melhorar', 'futuro melhor', 'acredito',
            'confio', 'vou conseguir', 'seguir em frente'
        ],
        'social_support': [
            'minha fam√≠lia', 'meus amigos', 'me apoiam', 'conversando com',
            'n√£o estou sozinho', 'tenho ajuda'
        ],
        'coping': [
            'medita√ß√£o', 'exerc√≠cio', 'terapia', 'respira√ß√£o', 'conversar',
            'escrever', 'm√∫sica', 'caminhar'
        ],
        'achievement': [
            'consegui', 'orgulhoso', 'melhor', 'progresso', 'superei',
            'realizei'
        ]
    }

    # =====================================================================
    # M√âTODOS PRINCIPAIS
    # =====================================================================

    @staticmethod
    def analyze_message(text: str) -> Dict:
        """
        An√°lise completa de uma mensagem

        Retorna:
        {
            'sentiment_score': float (-1 a 1),
            'sentiment_label': str,
            'danger_flags': List[str],
            'detected_keywords': List[str],
            'risk_level': str,
            'entities': Dict,
            'topics': List[str]
        }
        """
        # 1. An√°lise de sentimento
        sentiment_score, sentiment_label = NLPService.analyze_sentiment_simple(text)

        # 2. Detec√ß√£o de keywords perigosas
        danger_flags = NLPService.detect_danger_keywords(text)

        # 3. Detec√ß√£o de keywords gerais
        all_keywords = NLPService.extract_keywords(text)

        # 4. Calcular n√≠vel de risco
        risk_level = NLPService.calculate_risk_level(danger_flags, sentiment_score)

        # 5. Extra√ß√£o de entidades b√°sicas
        entities = NLPService.extract_entities_simple(text)

        # 6. Classifica√ß√£o de t√≥picos
        topics = NLPService.classify_topics(text)

        return {
            'sentiment_score': sentiment_score,
            'sentiment_label': sentiment_label,
            'danger_flags': danger_flags,
            'detected_keywords': all_keywords,
            'risk_level': risk_level,
            'entities': entities,
            'topics': topics,
            'analyzed_at': datetime.now().isoformat()
        }

    @staticmethod
    def analyze_sentiment_simple(text: str) -> Tuple[float, str]:
        """
        An√°lise de sentimento simples baseada em keywords
        (Para produ√ß√£o, usar modelo de ML)

        Returns: (score: float, label: str)
        """
        text_lower = text.lower()

        # Contar keywords positivas e negativas
        positive_count = 0
        negative_count = 0

        # Contar positivas
        for category, keywords in NLPService.POSITIVE_KEYWORDS.items():
            for keyword in keywords:
                if keyword in text_lower:
                    positive_count += 1

        # Contar negativas
        for category, keywords in NLPService.DANGER_KEYWORDS.items():
            for keyword in keywords:
                if keyword in text_lower:
                    negative_count += 2  # Peso maior para keywords perigosas

        # Palavras negativas comuns
        common_negative = ['n√£o', 'nunca', 'nada', 'triste', 'ruim', 'mal', 'dif√≠cil', 'problema']
        for word in common_negative:
            if f' {word} ' in f' {text_lower} ':
                negative_count += 0.5

        # Palavras positivas comuns
        common_positive = ['sim', 'bom', 'bem', 'feliz', 'alegre', '√≥timo', 'legal', 'gosto']
        for word in common_positive:
            if f' {word} ' in f' {text_lower} ':
                positive_count += 0.5

        # Calcular score normalizado (-1 a 1)
        total = positive_count + negative_count
        if total == 0:
            score = 0.0
            label = 'neutral'
        else:
            score = (positive_count - negative_count) / total
            score = max(-1.0, min(1.0, score))  # Clamp entre -1 e 1

            if score <= -0.6:
                label = 'very_negative'
            elif score <= -0.2:
                label = 'negative'
            elif score >= 0.6:
                label = 'very_positive'
            elif score >= 0.2:
                label = 'positive'
            else:
                label = 'neutral'

        return round(score, 4), label

    @staticmethod
    def detect_danger_keywords(text: str) -> List[str]:
        """
        Detectar keywords perigosas no texto

        Retorna lista de categorias de perigo detectadas
        """
        text_lower = text.lower()
        flags = []

        for category, keywords in NLPService.DANGER_KEYWORDS.items():
            for keyword in keywords:
                if keyword in text_lower:
                    if category not in flags:
                        flags.append(category)
                    break  # J√° detectou esta categoria

        return flags

    @staticmethod
    def extract_keywords(text: str) -> List[str]:
        """Extrair todas as keywords relevantes"""
        text_lower = text.lower()
        found_keywords = []

        # Verificar todas as keywords (positivas e negativas)
        all_keywords = {}
        all_keywords.update(NLPService.POSITIVE_KEYWORDS)
        all_keywords.update(NLPService.DANGER_KEYWORDS)

        for category, keywords in all_keywords.items():
            for keyword in keywords:
                if keyword in text_lower:
                    found_keywords.append(keyword)

        return list(set(found_keywords))  # Remover duplicatas

    @staticmethod
    def calculate_risk_level(danger_flags: List[str], sentiment_score: float) -> str:
        """
        Calcular n√≠vel de risco baseado em flags e sentimento

        Retorna: 'NONE', 'LOW', 'MODERATE', 'HIGH', 'CRITICAL'
        """
        # Risco cr√≠tico
        if 'suicidal_ideation' in danger_flags:
            return 'CRITICAL'
        if 'self_harm' in danger_flags:
            return 'CRITICAL'

        # Risco alto
        if 'hopelessness' in danger_flags and sentiment_score < -0.5:
            return 'HIGH'
        if len(danger_flags) >= 3:
            return 'HIGH'

        # Risco moderado
        if len(danger_flags) >= 1 and sentiment_score < -0.3:
            return 'MODERATE'
        if sentiment_score < -0.7:
            return 'MODERATE'

        # Risco baixo
        if len(danger_flags) >= 1 or sentiment_score < -0.2:
            return 'LOW'

        # Sem risco
        return 'NONE'

    @staticmethod
    def extract_entities_simple(text: str) -> Dict[str, List[str]]:
        """
        Extra√ß√£o simples de entidades
        (Para produ√ß√£o, usar spaCy ou similar)
        """
        entities = {
            'people': [],
            'emotions': [],
            'health_terms': [],
            'time_references': []
        }

        text_lower = text.lower()

        # Emo√ß√µes
        emotion_keywords = [
            'tristeza', 'alegria', 'raiva', 'medo', 'ansiedade', 'p√¢nico',
            'felicidade', 'amor', '√≥dio', 'frustra√ß√£o', 'al√≠vio', 'esperan√ßa'
        ]
        for emotion in emotion_keywords:
            if emotion in text_lower:
                entities['emotions'].append(emotion)

        # Termos de sa√∫de
        health_keywords = [
            'medicamento', 'terapia', 'm√©dico', 'psic√≥logo', 'psiquiatra',
            'hospital', 'consulta', 'tratamento', 'rem√©dio'
        ]
        for health_term in health_keywords:
            if health_term in text_lower:
                entities['health_terms'].append(health_term)

        # Refer√™ncias temporais
        time_keywords = ['hoje', 'ontem', 'amanh√£', 'semana', 'm√™s', 'ano']
        for time_ref in time_keywords:
            if time_ref in text_lower:
                entities['time_references'].append(time_ref)

        # Pessoas (regex simples para nomes pr√≥prios - b√°sico)
        # Padr√£o: palavra come√ßando com mai√∫scula
        name_pattern = r'\b[A-Z][a-z√°-√∫]+\b'
        potential_names = re.findall(name_pattern, text)
        entities['people'] = potential_names[:5]  # Limitar a 5

        return entities

    @staticmethod
    def classify_topics(text: str) -> List[str]:
        """
        Classifica√ß√£o de t√≥picos (simples, baseado em keywords)
        """
        topics = []
        text_lower = text.lower()

        topic_keywords = {
            'family': ['fam√≠lia', 'pai', 'm√£e', 'filho', 'filha', 'irm√£o', 'irm√£', 'neto', 'neta', 'esposa', 'marido'],
            'work': ['trabalho', 'emprego', 'chefe', 'colega', 'carreira', 'demiss√£o', 'desemprego'],
            'health': ['sa√∫de', 'doen√ßa', 'dor', 'sintoma', 'm√©dico', 'hospital', 'medicamento'],
            'death': ['morte', 'morrer', 'funeral', 'cemit√©rio', 'falecimento'],
            'relationships': ['relacionamento', 'namoro', 'casamento', 'amor', 't√©rmino', 'div√≥rcio'],
            'finances': ['dinheiro', 'd√≠vida', 'conta', 'desemprego', 'sal√°rio', 'financeiro'],
            'loneliness': ['solid√£o', 'sozinho', 'isolado', 'sem amigos'],
            'mental_health': ['depress√£o', 'ansiedade', 'p√¢nico', 'estresse', 'terapia', 'psic√≥logo']
        }

        for topic, keywords in topic_keywords.items():
            for keyword in keywords:
                if keyword in text_lower:
                    if topic not in topics:
                        topics.append(topic)
                    break

        return topics

    # =====================================================================
    # AN√ÅLISE DE CONVERSA√á√ÉO COMPLETA
    # =====================================================================

    @staticmethod
    def analyze_conversation(messages: List[Dict]) -> Dict:
        """
        An√°lisar uma conversa√ß√£o completa (m√∫ltiplas mensagens)

        Args:
            messages: Lista de dicts {'text': str, 'timestamp': datetime, 'role': str}

        Returns:
            An√°lise agregada da conversa√ß√£o
        """
        if not messages:
            return {'error': 'no_messages'}

        # Filtrar apenas mensagens do paciente
        patient_messages = [m for m in messages if m.get('role') == 'user' or m.get('role') == 'patient']

        if not patient_messages:
            return {'error': 'no_patient_messages'}

        # An√°lise de cada mensagem
        analyses = []
        for msg in patient_messages:
            analysis = NLPService.analyze_message(msg['text'])
            analysis['timestamp'] = msg.get('timestamp')
            analyses.append(analysis)

        # Agrega√ß√£o
        sentiment_scores = [a['sentiment_score'] for a in analyses]
        all_danger_flags = []
        for a in analyses:
            all_danger_flags.extend(a['danger_flags'])

        # Contar flags
        flag_counts = {}
        for flag in all_danger_flags:
            flag_counts[flag] = flag_counts.get(flag, 0) + 1

        # Calcular m√©dias
        avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0

        # Determinar tend√™ncia
        if len(sentiment_scores) >= 3:
            first_half = sentiment_scores[:len(sentiment_scores)//2]
            second_half = sentiment_scores[len(sentiment_scores)//2:]
            first_avg = sum(first_half) / len(first_half)
            second_avg = sum(second_half) / len(second_half)
            trend = 'improving' if second_avg > first_avg else ('worsening' if second_avg < first_avg else 'stable')
        else:
            trend = 'insufficient_data'

        # N√≠vel de risco geral
        if 'suicidal_ideation' in flag_counts or 'self_harm' in flag_counts:
            overall_risk = 'CRITICAL'
        elif len(flag_counts) >= 2 and avg_sentiment < -0.4:
            overall_risk = 'HIGH'
        elif len(flag_counts) >= 1 or avg_sentiment < -0.3:
            overall_risk = 'MODERATE'
        elif avg_sentiment < -0.1:
            overall_risk = 'LOW'
        else:
            overall_risk = 'NONE'

        return {
            'message_count': len(patient_messages),
            'avg_sentiment': round(avg_sentiment, 4),
            'sentiment_trend': trend,
            'danger_flag_counts': flag_counts,
            'overall_risk': overall_risk,
            'analyses': analyses
        }

    # =====================================================================
    # DETEC√á√ÉO DE MUDAN√áA DE PADR√ÉO
    # =====================================================================

    @staticmethod
    def detect_pattern_change(
        recent_analyses: List[Dict],
        baseline_analyses: List[Dict]
    ) -> Dict:
        """
        Detectar mudan√ßas de padr√£o entre baseline e per√≠odo recente

        Args:
            recent_analyses: An√°lises recentes (√∫ltimos 7 dias)
            baseline_analyses: An√°lises baseline (30-60 dias atr√°s)
        """
        if not recent_analyses or not baseline_analyses:
            return {'error': 'insufficient_data'}

        # Calcular m√©dias
        recent_sentiment = sum([a['sentiment_score'] for a in recent_analyses]) / len(recent_analyses)
        baseline_sentiment = sum([a['sentiment_score'] for a in baseline_analyses]) / len(baseline_analyses)

        # Diferen√ßa
        change = recent_sentiment - baseline_sentiment
        change_percentage = (change / abs(baseline_sentiment)) * 100 if baseline_sentiment != 0 else 0

        # Determinar se √© significativo (mudan√ßa > 30%)
        if abs(change_percentage) > 30:
            significant = True
            if change < 0:
                alert_message = f"‚ö†Ô∏è Piora significativa detectada: sentimento caiu {abs(change_percentage):.1f}%"
                alert_level = 'HIGH'
            else:
                alert_message = f"‚úÖ Melhora significativa detectada: sentimento subiu {change_percentage:.1f}%"
                alert_level = 'INFO'
        else:
            significant = False
            alert_message = "Padr√£o est√°vel, sem mudan√ßas significativas"
            alert_level = 'NONE'

        return {
            'significant_change': significant,
            'change_percentage': round(change_percentage, 2),
            'recent_avg_sentiment': round(recent_sentiment, 4),
            'baseline_avg_sentiment': round(baseline_sentiment, 4),
            'alert_message': alert_message,
            'alert_level': alert_level
        }


# =====================================================================
# FUN√á√ïES AUXILIARES PARA INTEGRA√á√ÉO
# =====================================================================

async def process_conversation_message_async(
    patient_id: int,
    message_text: str,
    session_id: Optional[int] = None,
    message_id: Optional[int] = None
) -> Dict:
    """
    Processar mensagem de conversa de forma ass√≠ncrona
    (Para usar com Celery ou task queue)
    """
    logger.info(f"Processando mensagem NLP para paciente {patient_id}")

    # An√°lise NLP
    analysis = NLPService.analyze_message(message_text)

    # Log se houver risco
    if analysis['risk_level'] in ['HIGH', 'CRITICAL']:
        logger.warning(
            f"üö® Risco {analysis['risk_level']} detectado - Paciente {patient_id} - "
            f"Flags: {analysis['danger_flags']}"
        )

    # TODO: Salvar an√°lise no banco de dados
    # await MentalHealthRepository.create_nlp_analysis(...)

    return analysis
